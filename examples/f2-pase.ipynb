{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "specified-ridge",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T18:50:21.534986Z",
     "iopub.status.busy": "2021-05-23T18:50:21.534328Z",
     "iopub.status.idle": "2021-05-23T18:50:23.394441Z",
     "shell.execute_reply": "2021-05-23T18:50:23.393897Z",
     "shell.execute_reply.started": "2021-05-23T18:09:38.430493Z"
    },
    "papermill": {
     "duration": 1.885944,
     "end_time": "2021-05-23T18:50:23.394629",
     "exception": false,
     "start_time": "2021-05-23T18:50:21.508685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from functools import lru_cache\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import scipy.fftpack\n",
    "import scipy.linalg\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intended-tuition",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T18:50:23.428888Z",
     "iopub.status.busy": "2021-05-23T18:50:23.428215Z",
     "iopub.status.idle": "2021-05-23T18:50:23.431672Z",
     "shell.execute_reply": "2021-05-23T18:50:23.431263Z",
     "shell.execute_reply.started": "2021-05-23T18:35:46.538851Z"
    },
    "papermill": {
     "duration": 0.0229,
     "end_time": "2021-05-23T18:50:23.431777",
     "exception": false,
     "start_time": "2021-05-23T18:50:23.408877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: QRNN ignores bidirectional flag\n",
      "Current Model keys:  78\n",
      "Current Pt keys:  78\n",
      "Loading matching keys:  ['denseskips.0.weight', 'denseskips.1.weight', 'denseskips.2.weight', 'denseskips.3.weight', 'denseskips.4.weight', 'denseskips.5.weight', 'denseskips.6.weight', 'blocks.0.conv.low_hz_', 'blocks.0.conv.band_hz_', 'blocks.0.norm.weight', 'blocks.0.norm.bias', 'blocks.0.norm.running_mean', 'blocks.0.norm.running_var', 'blocks.0.norm.num_batches_tracked', 'blocks.0.act.weight', 'blocks.1.conv.weight', 'blocks.1.conv.bias', 'blocks.1.norm.weight', 'blocks.1.norm.bias', 'blocks.1.norm.running_mean', 'blocks.1.norm.running_var', 'blocks.1.norm.num_batches_tracked', 'blocks.1.act.weight', 'blocks.2.conv.weight', 'blocks.2.conv.bias', 'blocks.2.norm.weight', 'blocks.2.norm.bias', 'blocks.2.norm.running_mean', 'blocks.2.norm.running_var', 'blocks.2.norm.num_batches_tracked', 'blocks.2.act.weight', 'blocks.3.conv.weight', 'blocks.3.conv.bias', 'blocks.3.norm.weight', 'blocks.3.norm.bias', 'blocks.3.norm.running_mean', 'blocks.3.norm.running_var', 'blocks.3.norm.num_batches_tracked', 'blocks.3.act.weight', 'blocks.4.conv.weight', 'blocks.4.conv.bias', 'blocks.4.norm.weight', 'blocks.4.norm.bias', 'blocks.4.norm.running_mean', 'blocks.4.norm.running_var', 'blocks.4.norm.num_batches_tracked', 'blocks.4.act.weight', 'blocks.5.conv.weight', 'blocks.5.conv.bias', 'blocks.5.norm.weight', 'blocks.5.norm.bias', 'blocks.5.norm.running_mean', 'blocks.5.norm.running_var', 'blocks.5.norm.num_batches_tracked', 'blocks.5.act.weight', 'blocks.6.conv.weight', 'blocks.6.conv.bias', 'blocks.6.norm.weight', 'blocks.6.norm.bias', 'blocks.6.norm.running_mean', 'blocks.6.norm.running_var', 'blocks.6.norm.num_batches_tracked', 'blocks.6.act.weight', 'blocks.7.conv.weight', 'blocks.7.conv.bias', 'blocks.7.norm.weight', 'blocks.7.norm.bias', 'blocks.7.norm.running_mean', 'blocks.7.norm.running_var', 'blocks.7.norm.num_batches_tracked', 'blocks.7.act.weight', 'rnn.layers.0.linear.weight', 'rnn.layers.0.linear.bias', 'W.weight', 'W.bias', 'norm_out.running_mean', 'norm_out.running_var', 'norm_out.num_batches_tracked']\n"
     ]
    }
   ],
   "source": [
    "# import pkg_resources\n",
    "# pkg_resources.get_distribution('pase').activate()\n",
    "import pase\n",
    "from pase.models.frontend import wf_builder\n",
    "\n",
    "# Install PyTorch QRRN for the PASE encoder\n",
    "# import torchqrnn\n",
    "from torchqrnn import QRNN\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../yaafelib/embed/\")\n",
    "\n",
    "from models import pnet,ModPASE\n",
    "from loader import Loader\n",
    "from trainer import train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading data\n",
    "train_dataset = Loader(args.train_path)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.num_workers, pin_memory=args.cuda, sampler=None)\n",
    "\n",
    "valid_dataset = Loader(args.valid_path)\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset, batch_size=args.batch_size, shuffle=None,\n",
    "    num_workers=args.num_workers, pin_memory=args.cuda, sampler=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13d9399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-pregnancy",
   "metadata": {
    "papermill": {
     "duration": 0.017578,
     "end_time": "2021-05-23T18:50:43.403333",
     "exception": false,
     "start_time": "2021-05-23T18:50:43.385755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Baseline model using a pre-trained [PASE+ model](https://github.com/santi-pdp/pase), LSTM, Average Poling, and Max Poling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "solved-plaza",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T18:50:43.582845Z",
     "iopub.status.busy": "2021-05-23T18:50:43.582080Z",
     "iopub.status.idle": "2021-05-23T18:50:43.584716Z",
     "shell.execute_reply": "2021-05-23T18:50:43.584281Z",
     "shell.execute_reply.started": "2021-05-23T18:09:59.227907Z"
    },
    "papermill": {
     "duration": 0.025221,
     "end_time": "2021-05-23T18:50:43.584818",
     "exception": false,
     "start_time": "2021-05-23T18:50:43.559597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    # general options\n",
    "    # train_path = traindf, #'../input/covid/train',         # train data folder\n",
    "    # valid_path = valdf,  #'../input/covid/valid',         # valid data folder\n",
    "    # test_path = tessdf,  #'../input/covid/test',           # test data folder\n",
    "    batch_size = 32,                             # training and valid batch size\n",
    "    test_batch_size = 20,                        # batch size for testing\n",
    "    arch = 'PASE',                               # PASE, VGG11, VGG13, VGG16, VGG19\n",
    "    epochs = 50,                                 # maximum number of epochs to train\n",
    "    lr = 0.0001,                                 # learning rate\n",
    "    momentum = 0.9,                              # SGD momentum, for SGD only\n",
    "    optimizer = 'adam',                          # optimization method: sgd | adam\n",
    "    seed = 1234,                                 # random seed\n",
    "    log_interval = 5,                            # how many batches to wait before logging training status\n",
    "    patience = 10,                               # how many epochs of no loss improvement should we wait before stop training\n",
    "    checkpoint = '.',                            # checkpoints directory\n",
    "    train = True,                                # train before testing\n",
    "    cuda = True,                                 # use gpu\n",
    "    num_workers = 2,                             # how many subprocesses to use for data loading\n",
    "    grad_clip = 1.0                             # gradient clipping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import traindf,testdf\n",
    "valdf,tessdf = train_test_split(testdf,test_size=0.5,shuffle=True)\n",
    "\n",
    "datalists = dict(\n",
    "    train = traindf,\n",
    "    test = tessdf,\n",
    "    val = valdf\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders  = {}\n",
    "for i,v in datalists.items():\n",
    "    # loading data\n",
    "    dataset = Loader(v)\n",
    "    dataloaders[i] =  torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.num_workers, pin_memory=args.cuda, sampler=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "feac0511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7fb994240b20>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7fb9d077e790>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x7fb99423c580>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "musical-turning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T18:50:43.674383Z",
     "iopub.status.busy": "2021-05-23T18:50:43.673703Z",
     "iopub.status.idle": "2021-05-23T18:50:49.760047Z",
     "shell.execute_reply": "2021-05-23T18:50:49.759593Z",
     "shell.execute_reply.started": "2021-05-23T18:09:59.243454Z"
    },
    "papermill": {
     "duration": 6.157737,
     "end_time": "2021-05-23T18:50:49.760172",
     "exception": false,
     "start_time": "2021-05-23T18:50:43.602435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA with 5 GPUs\n"
     ]
    }
   ],
   "source": [
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    print('Using CUDA with {0} GPUs'.format(torch.cuda.device_count()))\n",
    "\n",
    "\n",
    "# build model\n",
    "# freeze PASE+ parameters\n",
    "for param in pnet.parameters():\n",
    "    param.requires_grad = False\n",
    "if args.arch == 'PASE':\n",
    "    model = ModPASE(pnet,input_size=256,num_layers=3)\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "if torch.cuda.device_count()>1:\n",
    "    model = nn.DataParallel(model,device_ids=[0,1,2,3])\n",
    "\n",
    "# Define criterion\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean') # This loss combines a Sigmoid layer and the BCELoss in one single class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-yesterday",
   "metadata": {
    "papermill": {
     "duration": 0.018701,
     "end_time": "2021-05-23T18:50:49.798036",
     "exception": false,
     "start_time": "2021-05-23T18:50:49.779335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train model (Only new parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "emerging-frederick",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T18:50:50.017925Z",
     "iopub.status.busy": "2021-05-23T18:50:50.017329Z",
     "iopub.status.idle": "2021-05-23T19:24:21.122089Z",
     "shell.execute_reply": "2021-05-23T19:24:21.121628Z",
     "shell.execute_reply.started": "2021-05-23T18:46:08.865982Z"
    },
    "papermill": {
     "duration": 2011.26013,
     "end_time": "2021-05-23T19:24:21.122232",
     "exception": false,
     "start_time": "2021-05-23T18:50:49.862102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# define optimizer\n",
    "if args.optimizer.lower() == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "best_valid_auc = 0\n",
    "iteration = 0\n",
    "epoch = 1\n",
    "best_epoch = epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a6675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py:661: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1616554794034/work/aten/src/ATen/native/cudnn/RNN.cpp:915.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.6289, AUC: 44.3% (40.9% - 47.7%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_auc = test(valid_loader, model, criterion, cuda=True, data_set='Validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45089f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(args.checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d54a87af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py:661: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1616554794034/work/aten/src/ATen/native/cudnn/RNN.cpp:915.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [32/8858 (0%)]\tLoss: 0.638612\n",
      "Train Epoch: 1 [192/8858 (2%)]\tLoss: 0.611547\n",
      "Train Epoch: 1 [352/8858 (4%)]\tLoss: 0.602529\n",
      "Train Epoch: 1 [512/8858 (6%)]\tLoss: 0.591329\n",
      "Train Epoch: 1 [672/8858 (8%)]\tLoss: 0.582785\n",
      "Train Epoch: 1 [832/8858 (9%)]\tLoss: 0.575609\n",
      "Train Epoch: 1 [992/8858 (11%)]\tLoss: 0.569960\n",
      "Train Epoch: 1 [1152/8858 (13%)]\tLoss: 0.559142\n",
      "Train Epoch: 1 [1312/8858 (15%)]\tLoss: 0.551947\n",
      "Train Epoch: 1 [1472/8858 (17%)]\tLoss: 0.543408\n",
      "Train Epoch: 1 [1632/8858 (18%)]\tLoss: 0.534049\n",
      "Train Epoch: 1 [1792/8858 (20%)]\tLoss: 0.522177\n",
      "Train Epoch: 1 [1952/8858 (22%)]\tLoss: 0.508827\n",
      "Train Epoch: 1 [2112/8858 (24%)]\tLoss: 0.496021\n",
      "Train Epoch: 1 [2272/8858 (26%)]\tLoss: 0.482382\n",
      "Train Epoch: 1 [2432/8858 (27%)]\tLoss: 0.466396\n",
      "Train Epoch: 1 [2592/8858 (29%)]\tLoss: 0.449046\n",
      "Train Epoch: 1 [2752/8858 (31%)]\tLoss: 0.432861\n",
      "Train Epoch: 1 [2912/8858 (33%)]\tLoss: 0.414957\n",
      "Train Epoch: 1 [3072/8858 (35%)]\tLoss: 0.396186\n",
      "Train Epoch: 1 [3232/8858 (36%)]\tLoss: 0.377425\n",
      "Train Epoch: 1 [3392/8858 (38%)]\tLoss: 0.355856\n",
      "Train Epoch: 1 [3552/8858 (40%)]\tLoss: 0.328832\n",
      "Train Epoch: 1 [3712/8858 (42%)]\tLoss: 0.307169\n",
      "Train Epoch: 1 [3872/8858 (44%)]\tLoss: 0.282332\n",
      "Train Epoch: 1 [4032/8858 (46%)]\tLoss: 0.253955\n",
      "Train Epoch: 1 [4192/8858 (47%)]\tLoss: 0.233163\n",
      "Train Epoch: 1 [4352/8858 (49%)]\tLoss: 0.203570\n",
      "Train Epoch: 1 [4512/8858 (51%)]\tLoss: 0.177140\n",
      "Train Epoch: 1 [4672/8858 (53%)]\tLoss: 0.145571\n",
      "Train Epoch: 1 [4832/8858 (55%)]\tLoss: 0.116681\n",
      "Train Epoch: 1 [4992/8858 (56%)]\tLoss: 0.085111\n",
      "Train Epoch: 1 [5152/8858 (58%)]\tLoss: 0.061652\n",
      "Train Epoch: 1 [5312/8858 (60%)]\tLoss: 0.033799\n",
      "Train Epoch: 1 [5472/8858 (62%)]\tLoss: 0.007913\n",
      "Train Epoch: 1 [5632/8858 (64%)]\tLoss: -0.024830\n",
      "Train Epoch: 1 [5792/8858 (65%)]\tLoss: -0.048237\n",
      "Train Epoch: 1 [5952/8858 (67%)]\tLoss: -0.076387\n",
      "Train Epoch: 1 [6112/8858 (69%)]\tLoss: -0.104015\n",
      "Train Epoch: 1 [6272/8858 (71%)]\tLoss: -0.129599\n",
      "Train Epoch: 1 [6432/8858 (73%)]\tLoss: -0.153802\n",
      "Train Epoch: 1 [6592/8858 (74%)]\tLoss: -0.188103\n",
      "Train Epoch: 1 [6752/8858 (76%)]\tLoss: -0.220776\n",
      "Train Epoch: 1 [6912/8858 (78%)]\tLoss: -0.256271\n",
      "Train Epoch: 1 [7072/8858 (80%)]\tLoss: -0.285462\n",
      "Train Epoch: 1 [7232/8858 (82%)]\tLoss: -0.317780\n",
      "Train Epoch: 1 [7392/8858 (83%)]\tLoss: -0.345119\n",
      "Train Epoch: 1 [7552/8858 (85%)]\tLoss: -0.370719\n",
      "Train Epoch: 1 [7712/8858 (87%)]\tLoss: -0.402491\n",
      "Train Epoch: 1 [7872/8858 (89%)]\tLoss: -0.425890\n",
      "Train Epoch: 1 [8032/8858 (91%)]\tLoss: -0.447850\n",
      "Train Epoch: 1 [8192/8858 (92%)]\tLoss: -0.476278\n",
      "Train Epoch: 1 [8352/8858 (94%)]\tLoss: -0.510762\n",
      "Train Epoch: 1 [8512/8858 (96%)]\tLoss: -0.552235\n",
      "Train Epoch: 1 [8672/8858 (98%)]\tLoss: -0.588116\n",
      "Train Epoch: 1 [8832/8858 (100%)]\tLoss: -0.622226\n",
      "\n",
      "Validation set: Average loss: -2.1367, AUC: 48.7% (45.2% - 52.1%)\n",
      "\n",
      "Saving state\n",
      "Elapsed seconds: (66s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py:661: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1616554794034/work/aten/src/ATen/native/cudnn/RNN.cpp:915.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [32/8858 (0%)]\tLoss: -2.525781\n",
      "Train Epoch: 2 [192/8858 (2%)]\tLoss: -1.903462\n",
      "Train Epoch: 2 [352/8858 (4%)]\tLoss: -2.091013\n",
      "Train Epoch: 2 [512/8858 (6%)]\tLoss: -2.210904\n",
      "Train Epoch: 2 [672/8858 (8%)]\tLoss: -2.309427\n",
      "Train Epoch: 2 [832/8858 (9%)]\tLoss: -2.389638\n",
      "Train Epoch: 2 [992/8858 (11%)]\tLoss: -2.477279\n",
      "Train Epoch: 2 [1152/8858 (13%)]\tLoss: -2.446112\n",
      "Train Epoch: 2 [1312/8858 (15%)]\tLoss: -2.504596\n",
      "Train Epoch: 2 [1472/8858 (17%)]\tLoss: -2.563316\n",
      "Train Epoch: 2 [1632/8858 (18%)]\tLoss: -2.565585\n",
      "Train Epoch: 2 [1792/8858 (20%)]\tLoss: -2.544661\n",
      "Train Epoch: 2 [1952/8858 (22%)]\tLoss: -2.554207\n",
      "Train Epoch: 2 [2112/8858 (24%)]\tLoss: -2.571757\n",
      "Train Epoch: 2 [2272/8858 (26%)]\tLoss: -2.593567\n",
      "Train Epoch: 2 [2432/8858 (27%)]\tLoss: -2.596220\n",
      "Train Epoch: 2 [2592/8858 (29%)]\tLoss: -2.627292\n",
      "Train Epoch: 2 [2752/8858 (31%)]\tLoss: -2.652195\n",
      "Train Epoch: 2 [2912/8858 (33%)]\tLoss: -2.710829\n",
      "Train Epoch: 2 [3072/8858 (35%)]\tLoss: -2.760823\n",
      "Train Epoch: 2 [3232/8858 (36%)]\tLoss: -2.785440\n",
      "Train Epoch: 2 [3392/8858 (38%)]\tLoss: -2.827994\n",
      "Train Epoch: 2 [3552/8858 (40%)]\tLoss: -2.880735\n",
      "Train Epoch: 2 [3712/8858 (42%)]\tLoss: -2.910770\n",
      "Train Epoch: 2 [3872/8858 (44%)]\tLoss: -2.952292\n",
      "Train Epoch: 2 [4032/8858 (46%)]\tLoss: -2.997379\n",
      "Train Epoch: 2 [4192/8858 (47%)]\tLoss: -3.068142\n",
      "Train Epoch: 2 [4352/8858 (49%)]\tLoss: -3.055679\n",
      "Train Epoch: 2 [4512/8858 (51%)]\tLoss: -3.110615\n",
      "Train Epoch: 2 [4672/8858 (53%)]\tLoss: -3.133653\n",
      "Train Epoch: 2 [4832/8858 (55%)]\tLoss: -3.177217\n",
      "Train Epoch: 2 [4992/8858 (56%)]\tLoss: -3.223663\n",
      "Train Epoch: 2 [5152/8858 (58%)]\tLoss: -3.282075\n",
      "Train Epoch: 2 [5312/8858 (60%)]\tLoss: -3.339863\n",
      "Train Epoch: 2 [5472/8858 (62%)]\tLoss: -3.367878\n",
      "Train Epoch: 2 [5632/8858 (64%)]\tLoss: -3.383268\n",
      "Train Epoch: 2 [5792/8858 (65%)]\tLoss: -3.422470\n",
      "Train Epoch: 2 [5952/8858 (67%)]\tLoss: -3.462311\n",
      "Train Epoch: 2 [6112/8858 (69%)]\tLoss: -3.516566\n",
      "Train Epoch: 2 [6272/8858 (71%)]\tLoss: -3.549446\n",
      "Train Epoch: 2 [6432/8858 (73%)]\tLoss: -3.576060\n",
      "Train Epoch: 2 [6592/8858 (74%)]\tLoss: -3.624842\n",
      "Train Epoch: 2 [6752/8858 (76%)]\tLoss: -3.673749\n",
      "Train Epoch: 2 [6912/8858 (78%)]\tLoss: -3.729509\n",
      "Train Epoch: 2 [7072/8858 (80%)]\tLoss: -3.774939\n",
      "Train Epoch: 2 [7232/8858 (82%)]\tLoss: -3.814700\n",
      "Train Epoch: 2 [7392/8858 (83%)]\tLoss: -3.851722\n",
      "Train Epoch: 2 [7552/8858 (85%)]\tLoss: -3.903690\n",
      "Train Epoch: 2 [7712/8858 (87%)]\tLoss: -3.937105\n",
      "Train Epoch: 2 [7872/8858 (89%)]\tLoss: -3.968456\n",
      "Train Epoch: 2 [8032/8858 (91%)]\tLoss: -4.019861\n",
      "Train Epoch: 2 [8192/8858 (92%)]\tLoss: -4.059362\n",
      "Train Epoch: 2 [8352/8858 (94%)]\tLoss: -4.111321\n",
      "Train Epoch: 2 [8512/8858 (96%)]\tLoss: -4.166864\n",
      "Train Epoch: 2 [8672/8858 (98%)]\tLoss: -4.213190\n",
      "Train Epoch: 2 [8832/8858 (100%)]\tLoss: -4.252391\n",
      "\n",
      "Validation set: Average loss: -6.6372, AUC: 48.5% (45.0% - 52.0%)\n",
      "\n",
      "AUC was not improved, iteration 1\n",
      "Elapsed seconds: (135s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/rnn.py:661: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1616554794034/work/aten/src/ATen/native/cudnn/RNN.cpp:915.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [32/8858 (0%)]\tLoss: -6.869606\n",
      "Train Epoch: 3 [192/8858 (2%)]\tLoss: -6.643832\n",
      "Train Epoch: 3 [352/8858 (4%)]\tLoss: -7.144487\n",
      "Train Epoch: 3 [512/8858 (6%)]\tLoss: -7.427360\n",
      "Train Epoch: 3 [672/8858 (8%)]\tLoss: -7.086091\n",
      "Train Epoch: 3 [832/8858 (9%)]\tLoss: -7.053383\n",
      "Train Epoch: 3 [992/8858 (11%)]\tLoss: -7.130644\n",
      "Train Epoch: 3 [1152/8858 (13%)]\tLoss: -7.168699\n",
      "Train Epoch: 3 [1312/8858 (15%)]\tLoss: -7.221560\n",
      "Train Epoch: 3 [1472/8858 (17%)]\tLoss: -7.205783\n",
      "Train Epoch: 3 [1632/8858 (18%)]\tLoss: -7.224622\n",
      "Train Epoch: 3 [1792/8858 (20%)]\tLoss: -7.342848\n",
      "Train Epoch: 3 [1952/8858 (22%)]\tLoss: -7.542194\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shubham/strial-osaki/dnnd-hs-audio-features/examples/f2-pase.ipynb Cell 12'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B43.4.5.178/home/shubham/strial-osaki/dnnd-hs-audio-features/examples/f2-pase.ipynb#ch0000045vscode-remote?line=1'>2</a>\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B43.4.5.178/home/shubham/strial-osaki/dnnd-hs-audio-features/examples/f2-pase.ipynb#ch0000045vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mwhile\u001b[39;00m (epoch \u001b[39m<\u001b[39m args\u001b[39m.\u001b[39mepochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mand\u001b[39;00m (iteration \u001b[39m<\u001b[39m args\u001b[39m.\u001b[39mpatience):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B43.4.5.178/home/shubham/strial-osaki/dnnd-hs-audio-features/examples/f2-pase.ipynb#ch0000045vscode-remote?line=3'>4</a>\u001b[0m     train(train_loader, model, criterion, optimizer, epoch, args\u001b[39m.\u001b[39;49mcuda, args\u001b[39m.\u001b[39;49mlog_interval)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B43.4.5.178/home/shubham/strial-osaki/dnnd-hs-audio-features/examples/f2-pase.ipynb#ch0000045vscode-remote?line=4'>5</a>\u001b[0m         \u001b[39m# weight=train_dataset.weight)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B43.4.5.178/home/shubham/strial-osaki/dnnd-hs-audio-features/examples/f2-pase.ipynb#ch0000045vscode-remote?line=5'>6</a>\u001b[0m     valid_loss, valid_auc \u001b[39m=\u001b[39m test(valid_loader, model, criterion, args\u001b[39m.\u001b[39mcuda, data_set\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/strial-osaki/dnnd-hs-audio-features/examples/../yaafelib/embed/trainer.py:35\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loader, model, criterion, optimizer, epoch, cuda, log_interval, weight, max_norm, verbose)\u001b[0m\n\u001b[1;32m     <a href='file:///~/strial-osaki/dnnd-hs-audio-features/examples/../yaafelib/embed/trainer.py?line=32'>33</a>\u001b[0m     data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcuda(), target\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     <a href='file:///~/strial-osaki/dnnd-hs-audio-features/examples/../yaafelib/embed/trainer.py?line=33'>34</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='file:///~/strial-osaki/dnnd-hs-audio-features/examples/../yaafelib/embed/trainer.py?line=34'>35</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='file:///~/strial-osaki/dnnd-hs-audio-features/examples/../yaafelib/embed/trainer.py?line=35'>36</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m     <a href='file:///~/strial-osaki/dnnd-hs-audio-features/examples/../yaafelib/embed/trainer.py?line=36'>37</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=886'>887</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=887'>888</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=888'>889</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=889'>890</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=890'>891</a>\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=891'>892</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=892'>893</a>\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:167\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py?line=164'>165</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs[\u001b[39m0\u001b[39m])\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py?line=165'>166</a>\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py?line=166'>167</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_apply(replicas, inputs, kwargs)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py?line=167'>168</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather(outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:177\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py?line=175'>176</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparallel_apply\u001b[39m(\u001b[39mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py?line=176'>177</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids[:\u001b[39mlen\u001b[39;49m(replicas)])\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:78\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py?line=75'>76</a>\u001b[0m         thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py?line=76'>77</a>\u001b[0m     \u001b[39mfor\u001b[39;00m thread \u001b[39min\u001b[39;00m threads:\n\u001b[0;32m---> <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py?line=77'>78</a>\u001b[0m         thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py?line=78'>79</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py?line=79'>80</a>\u001b[0m     _worker(\u001b[39m0\u001b[39m, modules[\u001b[39m0\u001b[39m], inputs[\u001b[39m0\u001b[39m], kwargs_tup[\u001b[39m0\u001b[39m], devices[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/threading.py:1053\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1049'>1050</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1051'>1052</a>\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1052'>1053</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1053'>1054</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1054'>1055</a>\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1055'>1056</a>\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1056'>1057</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/threading.py:1073\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1069'>1070</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1071'>1072</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1072'>1073</a>\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1073'>1074</a>\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/torch/lib/python3.9/threading.py?line=1074'>1075</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# trainint with early stopping\n",
    "t0 = time.time()\n",
    "while (epoch < args.epochs + 1) and (iteration < args.patience):\n",
    "    train(train_loader, model, criterion, optimizer, epoch, args.cuda, args.log_interval)\n",
    "        # weight=train_dataset.weight)\n",
    "    valid_loss, valid_auc = test(valid_loader, model, criterion, args.cuda, data_set='Validation')\n",
    "\n",
    "\n",
    "    ## saving\n",
    "    if not os.path.isdir(args.checkpoint):\n",
    "        os.mkdir(args.checkpoint)\n",
    "    torch.save(model.state_dict(), './{}/model{:03d}.pt'.format(args.checkpoint, epoch))\n",
    "    if valid_auc <= best_valid_auc:\n",
    "        iteration += 1\n",
    "        print('AUC was not improved, iteration {0}'.format(str(iteration)))\n",
    "    else:\n",
    "        print('Saving state')\n",
    "        iteration = 0\n",
    "        best_valid_auc = valid_auc\n",
    "        best_epoch = epoch\n",
    "        state = {\n",
    "            'valid_auc': valid_auc,\n",
    "            'valid_loss': valid_loss,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir(args.checkpoint):\n",
    "            os.mkdir(args.checkpoint)\n",
    "        torch.save(state, './{}/ckpt.pt'.format(args.checkpoint))\n",
    "    epoch += 1\n",
    "    print(f'Elapsed seconds: ({time.time() - t0:.0f}s)')\n",
    "print(f'Best AUC: {best_valid_auc*100:.1f}% on epoch {best_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "temporal-notice",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:24:21.590248Z",
     "iopub.status.busy": "2021-05-23T19:24:21.589736Z",
     "iopub.status.idle": "2021-05-23T19:24:21.593736Z",
     "shell.execute_reply": "2021-05-23T19:24:21.593331Z",
     "shell.execute_reply.started": "2021-05-23T18:47:41.453079Z"
    },
    "papermill": {
     "duration": 0.238306,
     "end_time": "2021-05-23T19:24:21.593846",
     "exception": false,
     "start_time": "2021-05-23T19:24:21.355540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 71.0% on epoch 28\n"
     ]
    }
   ],
   "source": [
    "print(f'Best AUC: {best_valid_auc*100:.1f}% on epoch {best_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-theology",
   "metadata": {
    "papermill": {
     "duration": 0.239225,
     "end_time": "2021-05-23T19:24:22.066356",
     "exception": false,
     "start_time": "2021-05-23T19:24:21.827131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "swiss-lexington",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T19:24:22.544725Z",
     "iopub.status.busy": "2021-05-23T19:24:22.544184Z",
     "iopub.status.idle": "2021-05-23T19:24:31.653027Z",
     "shell.execute_reply": "2021-05-23T19:24:31.651738Z"
    },
    "papermill": {
     "duration": 9.34745,
     "end_time": "2021-05-23T19:24:31.653209",
     "exception": false,
     "start_time": "2021-05-23T19:24:22.305759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model (epoch 28)\n",
      "Saving results in submission.csv\n"
     ]
    }
   ],
   "source": [
    "test_dataset = Loader(args.test_path)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=args.test_batch_size, shuffle=None,\n",
    "    num_workers=args.num_workers, pin_memory=args.cuda, sampler=None)\n",
    "\n",
    "# get best epoch and model\n",
    "state = torch.load('./{}/ckpt.pt'.format(args.checkpoint))\n",
    "epoch = state['epoch']\n",
    "print(\"Testing model (epoch {})\".format(epoch))\n",
    "model.load_state_dict(torch.load('./{}/model{:03d}.pt'.format(args.checkpoint, epoch)))\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "results = 'submission.csv'\n",
    "print(\"Saving results in {}\".format(results))\n",
    "test(test_loader, model, criterion, args.cuda, save=results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2058.288065,
   "end_time": "2021-05-23T19:24:33.368652",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-23T18:50:15.080587",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
